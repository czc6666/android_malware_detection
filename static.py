# coding=utf-8
import os
from time import sleep

# root 主路径可以放在机械硬盘
root = '/home/czc/code/Android_Malware_Detection/'
# root1 高速缓冲文件路径，需要放在固态硬盘
root1 = '/home/czc/code/Android_Malware_Detection/'

data_root_path = root + 'dataset/'  # 数据集存放位置
apktool_root_path = root + 'apk_tool/'  # apktool存放位置
java_root_path = root + 'java/'  # java存放位置
_3rd_root_path = root + '3rd/'  # 第三方库存放位置
permission_feature_path = root + 'permission/'  # 权限特征存放位置
token_path_root = root + 'tokenResult/'  # token结果存放位置
cscg_root_path = root + 'class_set_call_graph/'  # 类集调用图存放位置
token_class_set_root_path = root + 'tokenClassSet/'  # token类集存放位置
java_src_tmp_path = root1 + 'java_src_tmp'  # java源码临时存放位置
model_path_prefix = root + 'model/'  # 模型存放位置
filelist_root = 'data/'  # 文件列表存放位置
ts_max = 1500  
ts_min = 100  
total_process_multi_core = 8  # 支持多核心调度的子进程的数量，如apktool, jadx等
total_process_single_core = 50  # 不支持多核心调度的子进程数量，如CSCG构建等
MainDirMaxToken = 30000  # 主目录最大token数
MaxToken = 100000  # 最大token数
MaxNodes = 1800  # 最大节点数
num_topics = 500  # 主题数
min_k_tmp_file = 'CSCG/min_k_tmp.txt'  # 最小k值临时文件

tfidf_dict_para = {
    'AMD_AndroZoo_demo':                 {'no_below': 1,   'no_above':  0.5},  # 这个数据集有大概50个apk，词频低于1的词将被忽略，词频高于0.5的词将被忽略   
    'AMD_AndroZoo':                      {'no_below': 50,  'no_above':  0.3},  # 这个数据集大概有15000个apk，词频低于50的词将被忽略，词频高于0.3的词将被忽略
    'Drebin_AndroZoo':                   {'no_below': 40,  'no_above':  0.5},  # 这个数据集大概有12000个apk，词频低于40的词将被忽略，词频高于0.5的词将被忽略
    'VirusShare_Apkpure':                {'no_below': 100, 'no_above':  0.5},  # 这个数据集大概有15000个apk，词频低于100的词将被忽略，词频高于0.5的词将被忽略
    'b':                     {'no_below': 5,   'no_above':  0.4},  # 这个数据集大概有1500个apk，词频低于5的词将被忽略，词频高于0.4的词将被忽略
    'czc_dataset_2':                     {'no_below': 2,   'no_above':  0.5},  # 这个数据集大概有140个apk，词频低于2的词将被忽略，词频高于0.5的词将被忽略
    'VirusShare_Android_APK_2022-1':     {'no_below': 2,   'no_above':  0.5},  # 这个数据集大概有140个apk，词频低于2的词将被忽略，词频高于0.5的词将被忽略
    'czc_dataset_4':                     {'no_below': 30,  'no_above':  0.5},  # 这个数据集大概有5000个apk，词频低于30的词将被忽略，词频高于0.5的词将被忽略
    'czc_dataset_3':                     {'no_below': 7,   'no_above':  0.5},  # 这个数据集大概有2000个apk，词频低于7的词将被忽略，词频高于0.5的词将被忽略
    'czc_dataset_5':                     {'no_below': 10,  'no_above':  0.5},  # 这个数据集大概有4500个apk，词频低于10的词将被忽略，词频高于0.5的词将被忽略
    'czc_dataset_6':                     {'no_below': 10,  'no_above':  0.5},  # 这个数据集大概有1500个apk，词频低于10的词将被忽略，词频高于0.5的词将被忽略
    'czc_dataset_7':                     {'no_below': 15,  'no_above':  0.5},  # 这个数据集大概有5000个apk，词频低于15的词将被忽略，词频高于0.5的词将被忽略
    '2010-2012_Drebin+AndroZoo':         {'no_below': 40,  'no_above':  0.5},  # 这个数据集大概有12000个apk，词频低于40的词将被忽略，词频高于0.5的词将被忽略
    '2013-2016-VirusShare+AndroZoo':     {'no_below': 40, 'no_above':  0.5},  # 这个数据集大概有21000个apk，词频低于40的词将被忽略，词频高于0.5的词将被忽略
    '2017-2018-CICMalware2020+AndroZoo':     {'no_below': 40, 'no_above':  0.5},  # 这个数据集大概有21000个apk，词频低于40的词将被忽略，词频高于0.5的词将被忽略
    '2019-2023-VirusShare+AndroZoo': {'no_below': 40, 'no_above':  0.5},  # 这个数据集大概有21000个apk，词频低于40的词将被忽略，词频高于0.5的词将被忽略
}  # 词典参数，no_below表示词频低于该值的词将被忽略，no_above表示词频高于该值的词将被忽略


def get_dataset_name():  # 选择数据集
    select = int(input(
        "🔍选择数据集：\n\
        1. 2010-2012_Drebin+AndroZoo\n\
        2. 2013-2016-VirusShare+AndroZoo\n\
        3. 2017-2018-CICMalware2020+AndroZoo\n\
        4. 2019-2023-VirusShare+AndroZoo\n\
        5. czc_dataset_7（小数据集，调试用）\n"))
    if select == 1:
        dataset_name = '2010-2012_Drebin+AndroZoo'
    elif select == 2:
        dataset_name = '2013-2016-VirusShare+AndroZoo'
    elif select == 3:
        dataset_name = '2017-2018-CICMalware2020+AndroZoo'
    elif select == 4:
        dataset_name = '2019-2023-VirusShare+AndroZoo'
    elif select == 5:
        dataset_name = 'czc_dataset_7'
    else:
        print("输入错误")
        raise Exception
    return dataset_name

def get_project_root():  # 获取项目根目录
    return root

def get_apk_path(dataset):  # 获取apk路径
    dataset_path_prefix = dataset + '/'  # 数据集路径前缀
    apk_path = data_root_path + dataset_path_prefix  # apk存放位置
    manifest_path = apktool_root_path + dataset_path_prefix + 'manifest/'  # manifest存放位置
    dex_path = apktool_root_path + dataset_path_prefix + 'dex/'  # dex存放位置
    java_path = java_root_path + dataset_path_prefix  # java存放位置
    _3rd_path = _3rd_root_path + dataset_path_prefix  # 第三方库存放位置
    permission_path = permission_feature_path + dataset_path_prefix  # 权限特征存放位置
    token_path = token_path_root + dataset_path_prefix  # token结果存放位置
    filelist_train = filelist_root + dataset + '_train.filelist'  # 训练集文件列表
    filelist_test = filelist_root + dataset + '_test.filelist'  # 测试集文件列表
    filelist_train_filter = filelist_root + dataset + '_train.filter'  # 训练集过滤后文件列表
    filelist_test_filter = filelist_root + dataset + '_test.filter'  # 测试集过滤后文件列表

    for path in [apk_path, manifest_path, dex_path, java_path, _3rd_path, permission_path, token_path]:  
        # 检查路径是否存在，不存在则创建
        if not os.path.exists(path):  # 检查路径是否存在
            os.system("mkdir -p " + path)  # 创建路径
    return apk_path, manifest_path, dex_path, java_path, _3rd_path, \
        permission_path, token_path, filelist_train, filelist_test, \
        filelist_train_filter, filelist_test_filter


# 2. 'cscg'表示对class-set提取lsi的配置
def get_lsi_config(dataset, type='lsi'):
    dataset_path_prefix = dataset + '/'
    train_file = filelist_root + dataset + '_train.filter'
    test_file = filelist_root + dataset + '_test.filter'
    if type == 'lsi':
        token_root = token_path_root + dataset_path_prefix
        model_root = model_path_prefix + dataset_path_prefix  # ['model_root']
    elif type == 'cscg':
        token_root = token_class_set_root_path + dataset_path_prefix
        model_root = model_path_prefix + dataset_path_prefix  # ['model_root']
    else:
        print('Only support "lsi" and "csbd", not include ' + type + '!')
        raise Exception
    if not os.path.exists(model_root):
        os.system('mkdir -p ' + model_root)
    TFIDF_dict_path = model_root + 'black_white_asm.dict'  # ['TFIDF_dict']
    dict_corpus = model_root + 'black_white_corpus.dict'  # ['dict_corpus']
    TFIDF_model = model_root + 'tfidf.model'  # ['TFIDF_model']
    TFIDF_corpus_path = model_root + 'black_white_corpus_tfidf.mm'  # ['TFIDF_corpus']
    LSI_model_path = model_root + 'lsi.model'  # ['LSI_model_path']
    no_below = tfidf_dict_para[dataset]['no_below']
    no_above = tfidf_dict_para[dataset]['no_above']

    if type == 'lsi':
        LSI_corpus_path = model_root + 'lsi_result.txt'  # ['LSI_corpus']
        LSI_corpus_path_test = model_root + 'lsi_result_test.txt'  # ['LSI_corpus_test']
    else:
        LSI_corpus_path = model_root + 'lsi_result/'  # ['LSI_corpus']
        LSI_corpus_path_test = model_root + 'lsi_result_test/'  # ['LSI_corpus_test']
        if not os.path.exists(LSI_corpus_path):
            os.mkdir(LSI_corpus_path)
        if not os.path.exists(LSI_corpus_path_test):
            os.mkdir(LSI_corpus_path_test)
    apktool_root = apktool_root_path + dataset_path_prefix

    return train_file, test_file, TFIDF_dict_path, dict_corpus, TFIDF_model, TFIDF_corpus_path, LSI_model_path, LSI_corpus_path, LSI_corpus_path_test, token_root, apktool_root, no_below, no_above

def get_xgboost_config(dataset_name):
    model_root = model_path_prefix + dataset_name + '/'
    LSI_Permission_file = model_root + 'lsi_permission.txt'  # ['LSI_Permission_file']
    LSI_per_xgboost_model = model_root + 'lsi_permission_xgboost.model'  # ['lsi_per_xgboost_model']
    LSI_corpus_path = model_root + 'lsi_result.txt'  # ['LSI_corpus']
    LSI_corpus_path_test = model_root + 'lsi_result_test.txt'  # ['LSI_corpus_test']
    LSI_Permission_file_test = model_root + 'lsi_permission_test.txt'  # ['LSI_Permission_file_test']
    permission_path = permission_feature_path + dataset_name +'/'
    return LSI_Permission_file, LSI_Permission_file_test, LSI_per_xgboost_model, LSI_corpus_path, LSI_corpus_path_test, permission_path


def get_cscg_config(dataset):
    dataset_path_prefix = dataset + '/'
    java_path = java_root_path + dataset_path_prefix
    java_graph_path = cscg_root_path + dataset_path_prefix
    _3rd_path = _3rd_root_path + dataset_path_prefix
    token_java_path = token_class_set_root_path + dataset_path_prefix

    for path in [java_path, java_graph_path, _3rd_path, token_java_path]:
        if not os.path.exists(path):
            os.system("mkdir -p " + path)

    return java_path, java_graph_path, _3rd_path, token_java_path


def get_graph_config(dataset):
    train_file = filelist_root + dataset + '_train.filter'
    test_file = filelist_root + dataset + '_test.filter'
    model_root = model_path_prefix + dataset + '/'  # ['model_root']
    graph_path = cscg_root_path + dataset + '/'

    if not os.path.exists(model_root):
        os.system('mkdir -p ' + model_root)
    LSI_corpus_path = model_root + 'lsi_result/'  # ['LSI_corpus']
    LSI_corpus_path_test = model_root + 'lsi_result_test/'  # ['LSI_corpus_test']
    if not os.path.exists(LSI_corpus_path):
        os.mkdir(LSI_corpus_path)
    if not os.path.exists(LSI_corpus_path_test):
        os.mkdir(LSI_corpus_path_test)
    train_lsi_fearue_file = model_root + 'lsi_result.txt'
    test_lsi_fearue_file = model_root + 'lsi_result_test.txt'
    permission_root = permission_feature_path + dataset + '/'
    return train_file, test_file, LSI_corpus_path, LSI_corpus_path_test, graph_path, model_root, permission_root, train_lsi_fearue_file, test_lsi_fearue_file
