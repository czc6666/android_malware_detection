# coding=utf-8
import os
import time
from multiprocessing import Pool
import sys

# 配置类
from static import get_apk_path, get_lsi_config, get_xgboost_config, get_cscg_config, get_graph_config
from static import total_process_multi_core, total_process_single_core, java_src_tmp_path, ts_max, min_k_tmp_file
from static import get_dataset_name

# 功能类 词法分析、权限提取、文件列表生成  2.py
from lexical_analysis.extract_token import extract_token
from Permission.permissionExtract import extractPermission
from dataset_construct.create_filelist import create_filelist

# 模型训练类 lsi 和 xgboost  3.py
from lsi.lsi import lsi_train, lsi_test
from xgb_classification.combine_lsi_permission import combine_lsi_permission
from xgb_classification.xgboost_clf import train_xgb_model, test_xgb_model

# cscg图构建类 4.py
from lsi.lsi import lsi_train, lsi_test_cscg
from CSCG.calculate_min_k import calculate_min_k
from CSCG.java_graph import get_cscg_dataset
from GAT.create_graph_dataset import create_graph_files

# 图神经网络类 5.py
from GAT.graph_net import graph_model

# 异常数据集清理类
from czc.dataset_clean.clean_label_from_apkset import clean_label

# 工具类
from Decompilation.apktool import apktool
from Decompilation.jar2java import jar2java
from czc.fun_timer import fun_timer, fun_timer_dict
program_root = os.getcwd()

# 添加apktool的环境变量
os.environ["PATH"] = program_root + '/tools/apktool/' + ":" + os.environ["PATH"]
# 添加jadx的环境变量
os.environ["PATH"] = program_root + '/tools/jadx/build/jadx/bin/' + ":" + os.environ["PATH"]


# 统计每个函数运行时间的字典
function_run_time_dict = {}


# 对原始APK文件进行预处理，包括反编译等
@fun_timer_dict(function_run_time_dict)
def preproces(dataset):

    print('🔍🔍🔍🔍🔍开始清理标签文件')
    time.sleep(2)
    clean_label(dataset)
    print('🔍🔍🔍🔍🔍清理标签文件完成')

    apk_path, manifest_path, dex_path, java_path, _3rd_path, permission_path, token_path, filelist_train, filelist_test, filelist_train_filter, filelist_test_filter = get_apk_path(dataset)

    # 2.使用apktool获取每个文件的Androidmanifest.xml和class.dex,在python2.7下运行
    # 提取xml和dex
    apktool(apk_path, manifest_path, dex_path, total_process_multi_core)

    # 3.使用jadx对每个class.dex进行反编译，并将反编译的全部java文件打包生成.zip的压缩包,在python3.6下运行
    # 反编译dex出java代码打包成zip
    jar2java(dex_path, java_path, java_src_tmp_path, program_root, total_process_multi_core)

    '''
    在DirAndFile.extractToken方法中，对于每个Java文件，它首先使用FileUtil.readFile读取文件内容，
    然后创建一个TestLexer实例，并调用analyse方法来提取tokens。
    提取的tokens被存储在DirAndFile.tokenResult列表中，最后这些tokens可以被写入到一个结果文件中。
    '''
    # 4.对每个反编译得到的java文件进行token提取,在python3.6下运行
    # 提取token，token也叫词法单元，通常包括关键字、标识符、常数、运算符等。
    extract_token(dataset, _3rd_path, java_path, manifest_path, token_path, total_process_single_core)

    # 5.对每个manifest文件提取权限特征,在python3.6下运行
    # 提取xml的权限特征，59维权限特征
    extractPermission(manifest_path, permission_path)

    # 6.生成记录每个数据集下全部有效数据的文件filelist.txt,在python3.6下运行（狗屁不通）
    # 😥创建过滤（第三方库）后的文件列表。。6.为训练数据集生成包含所有有效数据文件路径的filelist.txt文件（czc的注释）
    create_filelist(filelist_train, filelist_train_filter, _3rd_path, manifest_path, java_path)

    # 7.生成记录每个数据集下全部有效数据的文件filelist.txt,在python3.6下运行（狗屁不通）
    # 7.为测试数据集生成包含所有有效数据文件路径的filelist.txt文件（czc的注释）
    create_filelist(filelist_test, filelist_test_filter, _3rd_path, manifest_path, java_path)


# 仅使用语义模型和permission特征进行模型训练
@fun_timer_dict(function_run_time_dict)
def lsi_model_train(dataset):
    # 8.获取lsi模型训练所需全部文件的路径
    train_file, test_file, TFIDF_dict_path, dict_corpus, TFIDF_model_path, TFIDF_corpus_path, LSI_model_path, LSI_corpus_path, LSI_corpus_path_test, token_root, apktool_root_path, no_below, no_above = get_lsi_config(dataset)

    # 9.进行LSI模型的训练，内部包含TFIDF模型的训练，并生成训练特征文件
    lsi_train(dataset, train_file, TFIDF_dict_path, dict_corpus, TFIDF_model_path, TFIDF_corpus_path, LSI_model_path, LSI_corpus_path, token_root, no_below=no_below, no_above=no_above)

    # 10.生成测试集的特征向量
    lsi_test(dataset, test_file, TFIDF_dict_path, TFIDF_model_path, LSI_model_path, LSI_corpus_path_test, token_root)

    # 11.获取数据集与模型的相关信息
    LSI_Permission_file, LSI_Permission_file_test, lsi_per_xgboost_model, LSI_corpus_path, LSI_corpus_path_test, permission_dir_path = get_xgboost_config(dataset)

    # 12.生成lsi和permission拼接后训练集的特征
    combine_lsi_permission(dataset, LSI_corpus_path, permission_dir_path, LSI_Permission_file)

    # 13.生成测试集的lsi与permission拼接特征
    combine_lsi_permission(dataset, LSI_corpus_path_test, permission_dir_path, LSI_Permission_file_test)

    # 14.训练XGBoost模型进行分类
    train_xgb_model(LSI_Permission_file, lsi_per_xgboost_model)

    # 15.测试XGBoost模型的效果
    test_xgb_model(LSI_Permission_file_test, lsi_per_xgboost_model)


# 基于java文件的import关系进行图构建，相当于public class的调用关系，并保留一定的3rd库，使得过滤后节点数量小于100的，尽量补充到接近100
@fun_timer_dict(function_run_time_dict)
def class_set_call_graph(dataset):
    # dataset_name 数据集的名称,
    # java_path 原始java代码压缩包的存放路径,
    # java_graph_path 保存class-set call graph调用关系的路径,
    # _3rd_path 三方库文件的存放路径,
    # token_file_root 保存每个class-set的此法分析得到的tokens,
    # min_k 该数据集下的min_k值

    # 16.获取CSCG的配置信息
    print("🤣🤣🤣🤣🤣16.获取CSCG的配置信息")
    time.sleep(3)
    java_path, java_graph_path, _3rd_path, token_file_root= get_cscg_config(dataset)
    train_file, test_file, TFIDF_dict_path, dict_corpus, TFIDF_model_path, TFIDF_corpus_path, LSI_model_path, LSI_corpus_path, LSI_corpus_path_test, token_root, apktool_root_path, no_below, no_above = get_lsi_config(dataset, type='cscg')

    # 17.计算min_k
    print("🤣🤣🤣🤣🤣17.计算min_k")
    time.sleep(3)
    min_k = calculate_min_k(dataset, java_path, train_file, ts_max, min_k_tmp_file)

    # 18.计算CSCG调用图，并对节点进行分词
    print("🤣🤣🤣🤣🤣18.计算CSCG调用图，并对节点进行分词")
    time.sleep(3)
    get_cscg_dataset(dataset, java_path, java_graph_path, _3rd_path, token_file_root, min_k=min_k, total_process=total_process_single_core)

    # 提取class-set的LSI向量，每个APK保存成一个文件
    # pool = Pool(processes=2)
    # 19.生成训练集的节点特征向量
    print("🤣🤣🤣🤣🤣19.生成训练集的节点特征向量 train❗train❗train❗")
    time.sleep(3)
    lsi_test_cscg(dataset, train_file, TFIDF_dict_path, TFIDF_model_path, LSI_model_path, LSI_corpus_path, token_root, type='cscg')
    # pool.apply_async(lsi_test_cscg, (dataset, train_file, TFIDF_dict_path, TFIDF_model_path, LSI_model_path, LSI_corpus_path, token_root, 'cscg'))

    # 20.生成测试集的节点特征向量
    print("🤣🤣🤣🤣🤣20.生成测试集的节点特征向量 test❗test❗test❗")
    time.sleep(3)
    lsi_test_cscg(dataset, test_file, TFIDF_dict_path, TFIDF_model_path, LSI_model_path, LSI_corpus_path_test, token_root, type='cscg')
    # pool.apply_async(lsi_test_cscg, (dataset, test_file, TFIDF_dict_path, TFIDF_model_path, LSI_model_path, LSI_corpus_path_test, token_root, 'cscg'))
    # pool.close()
    # pool.join()

    # 防止多次调参时，读取碎文件太耗时间，因此先将CSCG保存成大文件
    print("🤣🤣🤣🤣🤣防止多次调参时，读取碎文件太耗时间，因此先将CSCG保存成大文件")
    time.sleep(3)
    # pool = Pool(processes=2)

    # 21.读取PSCN的输入graph源文件
    print("🤣🤣🤣🤣🤣21.读取PSCN的输入graph源文件")
    time.sleep(3)
    train_file, test_file, LSI_corpus_path, LSI_corpus_path_test, graph_file_root, model_root, permission_feature_path, lsi_fearue_file, lsi_fearue_file_test = get_graph_config(dataset)

    # 选择是否使用线程池执行22和23步
    use_pool = False

    if not use_pool:
        print("‼️❗‼️❗‼️❗‼️❗不使用进程池")
        # 22.生成训练集的graph文件
        print("🤣🤣🤣🤣🤣22.生成训练集的graph文件")
        time.sleep(5)
        create_graph_files(train_file, graph_file_root, LSI_corpus_path, model_root, lsi_fearue_file, permission_feature_path=permission_feature_path, type='cscg', apktool_root_path=apktool_root_path, add_root=False)
        # pool.apply_async(create_graph_files, (train_file, graph_file_root, LSI_corpus_path, model_root, lsi_fearue_file, permission_feature_path, 'cscg', apktool_root_path, False))

        # 23.生成测试集的graph文件
        print("🤣🤣🤣🤣🤣23.生成测试集的graph文件")
        time.sleep(5)
        create_graph_files(test_file, graph_file_root, LSI_corpus_path_test, model_root, lsi_fearue_file_test, permission_feature_path=permission_feature_path, type='cscg',  apktool_root_path=apktool_root_path)
        # pool.apply_async(create_graph_files, (test_file, graph_file_root, LSI_corpus_path_test, model_root, lsi_fearue_file_test, permission_feature_path, 'cscg', apktool_root_path, False))
        # pool.close()
        # pool.join()  
        # # czc: 如果使用进程池：这里生成训练集和生成测试集同时开始了，
        # # 到后面由于测试集数量少提前生成完毕结束，然后训练集的生成也同时结束，但此时训练集并没有生成完毕
        # # 训练集提前结束是因为某个xml有问题导致错误所以进程停止，但是测试集还在生成，所以造成这个现象

    else:
        print("‼️❗‼️❗‼️❗‼️❗使用进程池")
        # 使用进程池进行22和23步
        time.sleep(5)
        pool = Pool(processes=2)
        pool.apply_async(create_graph_files, (train_file, graph_file_root, LSI_corpus_path, model_root, lsi_fearue_file, permission_feature_path, 'cscg', apktool_root_path, False))
        create_graph_files(test_file, graph_file_root, LSI_corpus_path_test, model_root, lsi_fearue_file_test, permission_feature_path=permission_feature_path, type='cscg',  apktool_root_path=apktool_root_path)
        pool.close()
        pool.join()

# 基于java文的import关系进行图构建，相当于public class的调用关系，并保留一定的3rd库，使得过滤后节点数量小于100的，尽量补充到接近100
@fun_timer_dict(function_run_time_dict)
def class_set_call_graph_test(dataset):
    # 12.读取PSCN的输入graph源文件
    # czc-cursor：PSCH是public class的调用关系，并保留一定的3rd库，使得过滤后节点数量小于100的，尽量补充到接近100
    train_file, test_file, LSI_corpus_path, LSI_corpus_path_test, graph_file_root, \
    model_root, permission_feature_path, lsi_fearue_file, lsi_fearue_file_test = get_graph_config(dataset)

    # 15.graph_net训练测试
    graph_model(model_root, dataset)  # 训练和测试, 训练和测试的模型文件都保存在model_root目录下


@fun_timer_dict(function_run_time_dict)
def main():
    dataset = get_dataset_name()  # 从配置py获取数据集名称

    # 选择全流程执行或者单个函数执行
    select = int(input("🔍请选择执行的步骤：\n\
        1. 全流程执行\n\
        2. 单个函数执行\n"))
    if select == 1:  # 全流程执行
        # 2.py 对原始APK文件进行预处理，包括反编译等，源2.py
        preproces(dataset)  

        # 3.py 仅使用语义模型和permission特征进行模型训练，源3.py
        lsi_model_train(dataset)  

        # 4.py 基于java文件的import关系进行图构建，相当于public class的调用关系，
        # 并保留一定的3rd库，使得过滤后节点数量小于100的，尽量补充到接近100，源4.py
        class_set_call_graph(dataset)  

        # 5.py 基于java文的import关系进行图构建，相当于public class的调用关系，
        # 并保留一定的3rd库，使得过滤后节点数量小于100的，尽量补充到接近100，源5.py
        class_set_call_graph_test(dataset)  
    elif select == 2:  # 单个选择函数执行
        # 选择执行的函数
        function_select = int(input("🔍请选择执行的函数：\n\
            1. preproces：对原始APK文件进行预处理，包括反编译等\n\
            2. lsi_model_train：仅使用语义模型和permission特征进行模型训练\n\
            3. class_set_call_graph\n\
            4. class_set_call_graph_test\n"))
        if function_select == 1:
            preproces(dataset)
        elif function_select == 2:
            lsi_model_train(dataset)
        elif function_select == 3:
            class_set_call_graph(dataset)
        elif function_select == 4:
            class_set_call_graph_test(dataset)
    else:
        print("🔍输入错误，请重新输入")

if __name__ == '__main__':
    main()
    for function_name, run_time in function_run_time_dict.items():
        print(f"🤪🤪🤪🤪🤪{function_name} 运行时间: {run_time:.2f} 秒")
