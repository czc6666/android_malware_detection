import os
import numpy as np
import argparse
from os.path import join
import sys

from czc.memory_usage import memory_usage

def split_ids(ids):
    #import random
    n = len(ids)
    train_ids = ids[:int(0.9 * n)]
    #random.shuffle(train_ids)
    test_ids = ids[int(0.9 * n):]

    return train_ids, test_ids



class DataReader():  # 数据读取器
    '''

    名词：adjacency matrix：邻接矩阵（adj）

    Class to read the txt files containing all data of the dataset.
    Should work for any dataset from https://ls11-www.cs.tu-dortmund.de/staff/morris/graphkerneldatasets
    用于读取包含数据集所有数据的文本文件的类。
    应该适用于来自 https://ls11-www.cs.tu-dortmund.de/staff/morris/graphkerneldatasets 的任何数据集。

    让
    n = 节点总数
    m = 边总数
    N = 图表数量
    DS_A.txt （m 行）：所有图形的稀疏（块对角线）邻接矩阵，每行对应于 （row， col） 或 （node_id， node_id）。所有图形都是无向的。因此，DS_A.txt 包含每个边的两个条目。
    DS_graph_indicator.txt （n lines）：所有图的所有节点的图标识符的列向量，第 i 行的值是 i node_id的节点的graph_id
    DS_graph_labels.txt（N 行）：数据集中所有图形的类标签，第 i 行中的值是graph_id i 的图形的类标签
    DS_node_labels.txt（n 行）：节点标签的列向量，第 i 行的值对应于node_id为 i 的节点

    如果相应的信息可用，则有可选文件：
    DS_edge_labels.txt（m 线;与 DS_A_sparse.txt 相同）：DS_A_sparse.txt 中边缘的标签
    DS_edge_attributes.txt（m 线;与 DS_A.txt 相同）：DS_A.txt 中边缘的属性
    DS_node_attributes.txt（n 行）：节点属性矩阵，第 i 行中的逗号分隔值是node_id i 的节点的属性向量
    DS_graph_attributes.txt（N 行）：数据集中所有图形的回归值，第 i 行中的值是graph_id为 i 的图形的属性
    '''

    def __init__(self,
                 data_dir,  # 包含文本文件的文件夹 folder with txt files 
                 rnd_state=None,  # 随机种子
                 use_cont_node_attr=False,  # 是否使用连续节点属性
                 train_test='train_val',  # 训练集或测试集
                 use_node_labels=False  # 是否使用节点标签
                 # use or not additional float valued node attributes available in some datasets
                 # 在某些数据集中使用或不使用额外的浮点值节点属性。
                 ):

        self.data_dir = data_dir  # 包含文本文件的文件夹
        self.rnd_state = np.random.RandomState() if rnd_state is None else rnd_state  # 随机种子
        self.use_cont_node_attr = use_cont_node_attr  # 是否使用连续节点属性
        self.use_node_labels = use_node_labels  # 是否使用节点标签
        files = os.listdir(self.data_dir)  # 列出文件夹中的所有文件
        if train_test == 'train_val':  # 训练集
            file_prefix = '_train_'  # 文件前缀
        else:  # 测试集
            file_prefix = '_test_'  # 文件前缀
        data = {}  # 数据字典

        # 检查并读取 graph_indicator 文件
        graph_indicator_files = list(filter(lambda f: f.find(file_prefix + 'graph_indicator.txt') >= 0, files))
        if not graph_indicator_files:
            raise FileNotFoundError(f"未找到文件：{file_prefix + 'graph_indicator.txt'}")
        nodes, graphs, indexes = self.read_graph_nodes_relations(graph_indicator_files[0])

        # 检查并读取 A.txt 文件
        a_files = list(filter(lambda f: f.find(file_prefix + 'A.txt') >= 0, files))
        if not a_files:
            raise FileNotFoundError(f"未找到文件：{file_prefix + 'A.txt'}")
        data['adj_list'] = self.read_graph_adj(a_files[0], nodes, graphs, indexes)


        print('🔍🔍🔍🔍DataReader_GAT.py：读取图节点关系')
        nodes, graphs, indexes= self.read_graph_nodes_relations(list(filter(lambda f: f.find(file_prefix + 'graph_indicator.txt') >= 0, files))[0])  # 读取图节点关系
        print('+++++++++++++++++1')
        print(memory_usage())

        # data['adj_list'] = {}

        print('🔍🔍🔍🔍DataReader_GAT.py：读取图邻接矩阵')
        data['adj_list'] = self.read_graph_adj(list(filter(lambda f: f.find(file_prefix + 'A.txt') >= 0, files))[0], nodes, graphs, indexes) #, list(filter(lambda f: f.find(file_prefix + 'A2.txt') >= 0, files))[0])

        print('+++++++++++++++++2')
        print(memory_usage())

        print('Read adj list done!')  # 读取图邻接矩阵完成 （adjacency matrix）

        print('🔍🔍🔍🔍DataReader_GAT.py：读取图标签')
        data['targets'] = np.array(
            self.parse_txt_file(list(filter(lambda f: f.find(file_prefix + 'graph_labels') >= 0, files))[0],
                                line_parse_fn=lambda s: int(float(s.strip()))))
        
        print('+++++++++++++++++3')
        print(memory_usage())

        if self.use_cont_node_attr:
            print('🔍🔍🔍🔍DataReader_GAT.py：读取节点特征')
            data['attr'] = self.read_node_features(list(filter(lambda f: f.find(file_prefix + 'node_attributes.txt') >= 0, files))[0],
                                                   nodes, graphs,
                                                   fn=lambda s: np.array(list(map(float, s.strip().split(',')))))
            
        print('+++++++++++++++++4')
        print(memory_usage())

        print('Read node attri done!')  # 读取节点特征完成

        print('🔍🔍🔍🔍DataReader_GAT.py：读取图特征')
        data['graph_feature'] = np.array(
            self.parse_txt_file(list(filter(lambda f: f.find(file_prefix + 'graph_attributes.txt') >= 0, files))[0],
                                line_parse_fn=lambda s: [float(z) for z in s.split(',')]))
        
        print('+++++++++++++++++5')
        print(memory_usage())

        if self.use_node_labels:
            print('🔍🔍🔍🔍DataReader_GAT.py：读取节点标签')
            data['features'] = self.read_node_features(list(filter(lambda f: f.find(file_prefix + 'node_labels.txt') >= 0, files))[0], nodes, graphs, fn=lambda s: int(s.strip()))
        print(len(data['attr']))

        print('🔍🔍🔍🔍DataReader_GAT.py：创建特征')
        features, n_edges, degrees = [], [], []
        for sample_id, adj in enumerate(data['adj_list']):
            N = len(adj)  # number of nodes
            if self.use_node_labels:
                assert N == len(data['features'][sample_id]), (N, len(data['features'][sample_id]))
            # if not np.allclose(adj, adj.T):
            #     print(sample_id, 'not symmetric')
            n = np.sum(adj)  # total sum of edges
            # assert n % 2 == 0, n
            # n_edges.append(int(n / 2))  # undirected edges, so need to divide by 2
            n_edges.append(int(n))
            degrees.extend(list(np.sum(adj, 1)))
            if self.use_node_labels:
                features.append(np.array(data['features'][sample_id]))

        print('+++++++++++++++++6')
        print(memory_usage())

        # Create features over graphs as one-hot vectors for each node 在图上创建特征，作为每个节点的one-hot向量
        print('🔍🔍🔍🔍DataReader_GAT.py：在图形上创建特征，作为每个节点的单热向量')
        if self.use_node_labels:
            features_all = np.concatenate(features)
            features_min = features_all.min()
            num_features = int(features_all.max() - features_min + 1)  # number of possible values

        print('+++++++++++++++++7')
        print(memory_usage())

        max_degree = np.max(degrees)
        features_onehot = []  # 单热向量特征
        for sample_id, adj in enumerate(data['adj_list']):
            N = adj.shape[0]
            if self.use_node_labels:
                x = data['features'][sample_id]
                feature_onehot = np.zeros((len(x), num_features))
                for node, value in enumerate(x):
                    feature_onehot[node, value - features_min] = 1
            else:
                feature_onehot = np.empty((N, 0))
            if self.use_cont_node_attr:
                feature_attr = np.array(data['attr'][sample_id])
            else:
                feature_attr = np.empty((N, 0))
            degree_onehot = np.empty((N, 0))
            # print(sample_id)
            # print(feature_onehot.shape, feature_attr.shape, degree_onehot.shape)
            node_features = np.concatenate((feature_onehot, feature_attr, degree_onehot), axis=1)
            if node_features.shape[1] == 0:
                # dummy features for datasets without node labels/attributes
                # node degree features can be used instead
                node_features = np.ones((N, 1))
            features_onehot.append(node_features)

        print('+++++++++++++++++8')
        print(memory_usage())

        num_features = features_onehot[0].shape[1]

        shapes = [len(adj) for adj in data['adj_list']]
        labels = data['targets']  # graph class labels
        labels -= np.min(labels)  # to start from 0

        classes = np.unique(labels)
        num_classes = len(classes)

        print('+++++++++++++++++9')
        print(memory_usage())

        if not np.all(np.diff(classes) == 1):
            print('making labels sequential, otherwise pytorch might crash')
            labels_new = np.zeros(labels.shape, dtype=labels.dtype) - 1
            for lbl in range(num_classes):
                labels_new[labels == classes[lbl]] = lbl
            labels = labels_new
            classes = np.unique(labels)
            assert len(np.unique(labels)) == num_classes, np.unique(labels)

        def stats(x):
            return (np.mean(x), np.std(x), np.min(x), np.max(x))

        print('N nodes avg/std/min/max: \t%.2f/%.2f/%d/%d' % stats(shapes))
        print('N edges avg/std/min/max: \t%.2f/%.2f/%d/%d' % stats(n_edges))
        print('Node degree avg/std/min/max: \t%.2f/%.2f/%d/%d' % stats(degrees))
        print('Node features dim: \t\t%d' % num_features)
        print('N classes: \t\t\t%d' % num_classes)
        print('Classes: \t\t\t%s' % str(classes))
        for lbl in classes:
            print('Class %d: \t\t\t%d samples' % (lbl, np.sum(labels == lbl)))

        print('+++++++++++++++++10')
        print(memory_usage())

        N_graphs = len(labels)  # number of samples (graphs) in data
        print(N_graphs)
        print(len(data['adj_list']))
        print(len(features_onehot))
        assert N_graphs == len(data['adj_list']) == len(features_onehot), 'invalid data'

        # Create train/test sets first
        # if train_test == 'train_val':
        train_ids, val_ids = split_ids(rnd_state.permutation(N_graphs))
        # else:
        #     train_ids, val_ids = split_ids(N_graphs)

        print('+++++++++++++++++11')
        print(memory_usage())

        # Create train sets
        splits = {'train': list(train_ids), 'val': list(val_ids)}

        data['features_onehot'] = features_onehot
        data['targets'] = labels
        data['splits'] = splits
        data['N_nodes_max'] = np.max(shapes)  # max number of nodes
        data['num_features'] = num_features
        data['num_classes'] = num_classes

        print('+++++++++++++++++12')
        print(memory_usage())

        self.data = data

    def parse_txt_file(self, fpath, line_parse_fn=None):
        print(fpath)
        data = []
        count = 0
        with open(join(self.data_dir, fpath), 'r') as f:
        #     lines = f.readlines()
        # print('---')
        # data = [line_parse_fn(s) if line_parse_fn is not None else s for s in lines]
            while True:
                lines = f.readlines(10000)
                if not lines:
                    break
                for line in lines:
                    count += 1
                    if count % 1000000 == 0:
                        print(count)
                    data.append(line_parse_fn(line) if line_parse_fn is not None else line)
        return data
    def parse_txt_file_single(self, fpath, line_parse_fn=None):
        print(fpath)
        data = []
        count = 0
        with open(join(self.data_dir, fpath), 'r') as f:
        #     lines = f.readlines()
        # print('---')
        # data = [line_parse_fn(s) if line_parse_fn is not None else s for s in lines]
            while True:
                lines = f.readlines(10000)
                if not lines:
                    break
                for line in lines:
                    count += 1
                    if count % 1000000 == 0:
                        print(count)
                    yield line_parse_fn(line) if line_parse_fn is not None else line
        # return data

    # graph key is graph_id, value is list of nodes
    def read_graph_adj(self, fpath, nodes, graphs, indexes, fpath2=None):
        # edges = self.parse_txt_file(fpath, line_parse_fn=lambda s: [int(num.strip()) for num in s.split(',')])
        adj_dict = {}
        # 添加每个节点的自环
        # for node in nodes:
        #     edges.append((str(node), str(node)))
        # for edge in edges:
        for edge in self.parse_txt_file_single(fpath, line_parse_fn=lambda s: [int(num.strip()) for num in s.split(',')]):
            # print(edge)
            node1 = edge[0]#int(edge[0].strip())# - 1  # -1 because of zero-indexing in our code
            node2 = edge[1]#int(edge[1].strip())# - 1
            graph_id = nodes[node1]
            assert graph_id == nodes[node2], ('invalid data', graph_id, nodes[node2])
            if graph_id not in adj_dict:
                n = len(graphs[graph_id])
                # adj_dict[graph_id] = np.zeros((n, n))
                adj_dict[graph_id] = np.full((n, n), -1e9)
                # adj_dict[graph_id] = np.array(n * [n * [-1e9]])
                # print(adj_dict[graph_id].shape)
                # raise Exception
                # 添加每个节点的自环
                for i in range(n):
                    adj_dict[graph_id][i, i] = 0
            # ind1 = np.where(graphs[graph_id] == node1)[0]
            # ind2 = np.where(graphs[graph_id] == node2)[0]
            # print(ind2)
            ind1 = np.array([indexes[node1]])
            ind2 = np.array([indexes[node2]])
            # print(ind2)
            assert len(ind1) == len(ind2) == 1, (ind1, ind2)
            adj_dict[graph_id][ind1, ind2] = 0
            # pass

            # 转成无向图
            adj_dict[graph_id][ind2, ind1] = 0
        # print(adj_dict[0])
        # 添加节点特征关联
        # if fpath2 is not None:
        #     for edge in self.parse_txt_file_single(fpath2, line_parse_fn=lambda s: [int(num.strip()) for num in s.split(',')]):
        #
        #         # print(edge)
        #         node1 = edge[0]#int(edge[0].strip())# - 1  # -1 because of zero-indexing in our code
        #         node2 = edge[1]#int(edge[1].strip())# - 1
        #         graph_id = nodes[node1]
        #         assert graph_id == nodes[node2], ('invalid data', graph_id, nodes[node2])
        #         if graph_id not in adj_dict:
        #             n = len(graphs[graph_id])
        #             adj_dict[graph_id] = np.zeros((n, n))
        #         # ind1 = np.where(graphs[graph_id] == node1)[0]
        #         # ind2 = np.where(graphs[graph_id] == node2)[0]
        #         # print(ind2)
        #         ind1 = np.array([indexes[node1]])
        #         ind2 = np.array([indexes[node2]])
        #         # print(ind2)
        #         assert len(ind1) == len(ind2) == 1, (ind1, ind2)
        #         adj_dict[graph_id][ind1, ind2] = 1
        #         pass
        #
        #         # 转成无向图
        #         adj_dict[graph_id][ind2, ind1] = 1
        # print(adj_dict[0])
        for graph_id in graphs.keys():
            if graph_id not in adj_dict:
                n = len(graphs[graph_id])
                adj_dict[graph_id] = np.zeros((n, n))
        adj_list = [adj_dict[graph_id] for graph_id in sorted(list(graphs.keys()))]

        return adj_list

    def read_graph_nodes_relations(self, fpath):  # 读取图节点关系
        graph_ids = self.parse_txt_file(fpath, line_parse_fn=lambda s: int(s.rstrip()))  # 读取图节点关系
        nodes, graphs = {}, {}  # 节点和图的字典
        indexes = [0.0 for i in range(len(graph_ids))]  # 索引列表
        for node_id, graph_id in enumerate(graph_ids):  # 枚举图节点关系
            if graph_id not in graphs:  # 如果图不在图中，则添加
                graphs[graph_id] = []  # 添加图
            graphs[graph_id].append(node_id)  # 添加节点
            nodes[node_id] = graph_id  # 添加节点
            indexes[node_id] = len(graphs[graph_id]) - 1  # 添加索引
        graph_ids = np.unique(list(graphs.keys()))  # 获取图的唯一值
        for graph_id in graph_ids:  
            graphs[graph_id] = np.array(graphs[graph_id])
        return nodes, graphs, indexes

    def read_node_features(self, fpath, nodes, graphs, fn):  # 读取节点特征
        node_features_all = self.parse_txt_file(fpath, line_parse_fn=fn)
        node_features = {}
        for node_id, x in enumerate(node_features_all):
            graph_id = nodes[node_id]
            if graph_id not in node_features:
                node_features[graph_id] = [None] * len(graphs[graph_id])
            ind = np.where(graphs[graph_id] == node_id)[0]
            assert len(ind) == 1, ind
            assert node_features[graph_id][ind[0]] is None, node_features[graph_id][ind[0]]
            node_features[graph_id][ind[0]] = x
        node_features_lst = [node_features[graph_id] for graph_id in sorted(list(graphs.keys()))]
        return node_features_lst
