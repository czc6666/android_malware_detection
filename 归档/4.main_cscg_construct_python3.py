# coding=utf-8

"""
我修改了create_graph_files函数，在生成的时候记录错误apk信息并生成一个txt文件，函数结束后询问我是否删除错误apk
/home/czc/code/Android_Malware_Detection/code/android_malware_detection/data/error_apks.txt

这里取消了进程池，因为在跑的时候需要一个一个跑，用于获取错误apk的信息，保存文件在：
/home/czc/code/Android_Malware_Detection/code/android_malware_detection/data/error_apks.txt

如果第一遍跑过了，并删除了所有错误apk，可以用进程池来跑create_graph_files函数
（用进程池来跑我的后面要求输入是否删除错误apk的input方法会不会出问题????最好就分开跑吧）

202410272330
数据集：czc_dataset_VS_Drebin_AndroZoo 6000个apk，运行时间:  3000秒
总运行时间: 3158.55 秒

数据集：czc_dataset_4 6000个apk，运行时间: 664.65 秒
"""

import os
from multiprocessing import Pool
from static import get_lsi_config, get_cscg_config, get_graph_config
from static import total_process_multi_core, total_process_single_core, ts_max, min_k_tmp_file
from static import get_dataset_name
from lsi.lsi import lsi_train, lsi_test_cscg
from CSCG.calculate_min_k import calculate_min_k
from CSCG.java_graph import get_cscg_dataset
from GAT.create_graph_dataset import create_graph_files
import time

# 收集开始时间
start_time = time.time()

program_root = os.getcwd()
# 添加apktool的环境变量
os.environ["PATH"] = program_root + '/tools/apktool/' + ":" + os.environ["PATH"]
# 添加jadx的环境变量
os.environ["PATH"] = program_root + '/tools/jadx/build/jadx/bin/' + ":" + os.environ["PATH"]


# 基于java文件的import关系进行图构建，相当于public class的调用关系，并保留一定的3rd库，使得过滤后节点数量小于100的，尽量补充到接近100
def class_set_call_graph(dataset):
    # dataset_name 数据集的名称,
    # java_path 原始java代码压缩包的存放路径,
    # java_graph_path 保存class-set call graph调用关系的路径,
    # _3rd_path 三方库文件的存放路径,
    # token_file_root 保存每个class-set的此法分析得到的tokens,
    # min_k 该数据集下的min_k值

    # 16.获取CSCG的配置信息
    print("🤣🤣🤣🤣🤣16.获取CSCG的配置信息")
    time.sleep(3)
    java_path, java_graph_path, _3rd_path, token_file_root= get_cscg_config(dataset)
    train_file, test_file, TFIDF_dict_path, dict_corpus, TFIDF_model_path, TFIDF_corpus_path, LSI_model_path, LSI_corpus_path, LSI_corpus_path_test, token_root, apktool_root_path, no_below, no_above = get_lsi_config(dataset, type='cscg')

    # 17.计算min_k
    print("🤣🤣🤣🤣🤣17.计算min_k")
    time.sleep(3)
    min_k = calculate_min_k(dataset, java_path, train_file, ts_max, min_k_tmp_file)

    # 18.计算CSCG调用图，并对节点进行分词
    print("🤣🤣🤣🤣🤣18.计算CSCG调用图，并对节点进行分词")
    time.sleep(3)
    get_cscg_dataset(dataset, java_path, java_graph_path, _3rd_path, token_file_root, min_k=min_k, total_process=total_process_single_core)

    # 提取class-set的LSI向量，每个APK保存成一个文件
    # pool = Pool(processes=2)
    # 19.生成训练集的节点特征向量
    print("🤣🤣🤣🤣🤣19.生成训练集的节点特征向量 train❗train❗train❗")
    time.sleep(3)
    lsi_test_cscg(dataset, train_file, TFIDF_dict_path, TFIDF_model_path, LSI_model_path, LSI_corpus_path, token_root, type='cscg')
    # pool.apply_async(lsi_test_cscg, (dataset, train_file, TFIDF_dict_path, TFIDF_model_path, LSI_model_path, LSI_corpus_path, token_root, 'cscg'))

    # 20.生成测试集的节点特征向量
    print("🤣🤣🤣🤣🤣20.生成测试集的节点特征向量 test❗test❗test❗")
    time.sleep(3)
    lsi_test_cscg(dataset, test_file, TFIDF_dict_path, TFIDF_model_path, LSI_model_path, LSI_corpus_path_test, token_root, type='cscg')
    # pool.apply_async(lsi_test_cscg, (dataset, test_file, TFIDF_dict_path, TFIDF_model_path, LSI_model_path, LSI_corpus_path_test, token_root, 'cscg'))
    # pool.close()
    # pool.join()

    # 防止多次调参时，读取碎文件太耗时间，因此先将CSCG保存成大文件
    print("🤣🤣🤣🤣🤣防止多次调参时，读取碎文件太耗时间，因此先将CSCG保存成大文件")
    time.sleep(3)
    # pool = Pool(processes=2)

    # 21.读取PSCN的输入graph源文件
    print("🤣🤣🤣🤣🤣21.读取PSCN的输入graph源文件")
    time.sleep(3)
    train_file, test_file, LSI_corpus_path, LSI_corpus_path_test, graph_file_root, model_root, permission_feature_path, lsi_fearue_file, lsi_fearue_file_test = get_graph_config(dataset)

    # 选择是否使用线程池执行22和23步
    use_pool = False

    if not use_pool:
        print("‼️❗‼️❗‼️❗‼️❗不使用进程池")
        # 22.生成训练集的graph文件
        print("🤣🤣🤣🤣🤣22.生成训练集的graph文件")
        time.sleep(5)
        create_graph_files(train_file, graph_file_root, LSI_corpus_path, model_root, lsi_fearue_file, permission_feature_path=permission_feature_path, type='cscg', apktool_root_path=apktool_root_path, add_root=False)
        # pool.apply_async(create_graph_files, (train_file, graph_file_root, LSI_corpus_path, model_root, lsi_fearue_file, permission_feature_path, 'cscg', apktool_root_path, False))

        # 23.生成测试集的graph文件
        print("🤣🤣🤣🤣🤣23.生成测试集的graph文件")
        time.sleep(5)
        create_graph_files(test_file, graph_file_root, LSI_corpus_path_test, model_root, lsi_fearue_file_test, permission_feature_path=permission_feature_path, type='cscg',  apktool_root_path=apktool_root_path)
        # pool.apply_async(create_graph_files, (test_file, graph_file_root, LSI_corpus_path_test, model_root, lsi_fearue_file_test, permission_feature_path, 'cscg', apktool_root_path, False))
        # pool.close()
        # pool.join()  
        # # czc: 如果使用进程池：这里生成训练集和生成测试集同时开始了，
        # # 到后面由于测试集数量少提前生成完毕结束，然后训练集的生成也同时结束，但此时训练集并没有生成完毕
        # # 训练集提前结束是因为某个xml有问题导致错误所以进程停止，但是测试集还在生成，所以造成这个现象

    else:
        print("‼️❗‼️❗‼️❗‼️❗使用进程池")
        # 使用进程池进行22和23步
        time.sleep(5)
        pool = Pool(processes=2)
        pool.apply_async(create_graph_files, (train_file, graph_file_root, LSI_corpus_path, model_root, lsi_fearue_file, permission_feature_path, 'cscg', apktool_root_path, False))
        create_graph_files(test_file, graph_file_root, LSI_corpus_path_test, model_root, lsi_fearue_file_test, permission_feature_path=permission_feature_path, type='cscg',  apktool_root_path=apktool_root_path)
        pool.close()
        pool.join()




def main():
    dataset = get_dataset_name()
    class_set_call_graph(dataset)

    # 收集结束时间
    end_time = time.time()
    print("4.py的运行时间: {:.2f} 秒".format(end_time - start_time))


if __name__ == '__main__':
    main()



